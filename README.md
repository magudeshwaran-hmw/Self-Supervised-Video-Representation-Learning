# ğŸ¬ Self-Supervised Video Learning

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue?style=flat-square)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-ee4c2c?style=flat-square)](https://pytorch.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-Live_Demo-FF4B4B?style=flat-square)](https://streamlit.io)
[![License](https://img.shields.io/badge/License-MIT-green?style=flat-square)](LICENSE)

**Self-supervised video representation learning** with SimCLR, MoCo v2, BYOL, and VideoMAE. Interactive Streamlit UI for training, evaluation, and visualization.

![Architecture](screenshots/architecture.png)

---

## ğŸš€ Quick Start

```bash
# Install & Run
pip install -r requirements.txt
streamlit run app.py
```

**Deploy to Streamlit Cloud:**
1. Push to GitHub
2. Go to [share.streamlit.io](https://share.streamlit.io)
3. Click "New app" â†’ Select repo â†’ Set `app.py` â†’ Deploy

---

## âœ¨ Features

ğŸ¯ **4 SSL Methods** â€¢ ğŸ§  **Video Transformer** â€¢ ğŸ“Š **Real-time Training** â€¢ ğŸ”¬ **Feature Visualization** â€¢ ğŸ“ˆ **Evaluation Metrics**

---

## ğŸ“Š Results

<table>
<tr>
<td><img src="screenshots/training_loss.png" width="400"/></td>
<td><img src="screenshots/method_comparison.png" width="400"/></td>
</tr>
<tr>
<td><img src="screenshots/confusion_matrix.png" width="400"/></td>
<td><img src="screenshots/feature_space.png" width="400"/></td>
</tr>
</table>

![Video Frames](screenshots/video_frames.png)

---

## ğŸ—ï¸ Architecture

| Method | Strategy | Key Feature |
|--------|----------|-------------|
| **SimCLR** | Contrastive | NT-Xent loss |
| **MoCo v2** | Contrastive | Momentum encoder |
| **BYOL** | Predictive | No negatives |
| **VideoMAE** | Reconstructive | 75% masking |

---

## ğŸ“ Structure

```
â”œâ”€â”€ app.py              # Complete application
â”œâ”€â”€ requirements.txt    # Dependencies
â”œâ”€â”€ .streamlit/         # Config
â””â”€â”€ screenshots/        # Visualizations
```

---

## ğŸ® Usage

**Interactive UI:**
1. Configure parameters in sidebar
2. Click "ğŸš€ Train Model"
3. Click "ğŸ“Š Run Evaluation"
4. Explore visualizations

**Programmatic:**
```python
from app import build_model, SyntheticVideoDataset

model = build_model('simclr', img_size=64, num_frames=8)
dataset = SyntheticVideoDataset(num_videos=200)
```

---

## âš™ï¸ Configuration

| Parameter | Default | Options |
|-----------|---------|---------|
| Method | simclr | simclr, moco, byol, videomae |
| Resolution | 64 | 32, 64, 128 |
| Frames | 8 | 4, 8, 16 |
| Embed Dim | 192 | 96, 192, 384 |
| Depth | 4 | 2-8 |
| Epochs | 6 | 2-30 |

---

## ğŸ“š References

- **SimCLR**: [arXiv:2002.05709](https://arxiv.org/abs/2002.05709)
- **MoCo v2**: [arXiv:2003.04297](https://arxiv.org/abs/2003.04297)
- **BYOL**: [arXiv:2006.07733](https://arxiv.org/abs/2006.07733)
- **VideoMAE**: [arXiv:2203.12602](https://arxiv.org/abs/2203.12602)

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE)

**Made with â¤ï¸ using PyTorch & Streamlit**
